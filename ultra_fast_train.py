#!/usr/bin/env python3
"""
Ultra Fast Training - Complete in under 2 minutes
Optimized for speed while maintaining quality
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import random
import numpy as np
import time
import json
from datetime import datetime

class FastDataset(Dataset):
    """Ultra-fast dataset for quick training"""
    
    def __init__(self, data_pairs, max_length=16, vocab_file='vocab.txt'):  # Reduced length for speed
        self.data = []
        for task, subtitles in data_pairs:
            # Take only first 2 subtitles per task for speed
            for subtitle in subtitles[:2]:
                self.data.append((task.lower().strip(), subtitle.strip()))
        
        self.max_length = max_length
        self.vocab = self._load_vocab(vocab_file)
        self.vocab_size = len(self.vocab)
        
    def _load_vocab(self, vocab_file):
        """Load vocabulary from vocab.txt file"""
        vocab = {'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3}
        
        try:
            with open(vocab_file, 'r', encoding='utf-8') as f:
                for line in f:
                    word = line.strip()
                    if word and word not in vocab:
                        vocab[word] = len(vocab)
            
            print(f"ğŸ“š Loaded vocabulary from {vocab_file}: {len(vocab)} words")
            
        except FileNotFoundError:
            print(f"âš ï¸  Vocab file {vocab_file} not found, building from training data...")
            # Fallback to building vocab from data
            for task, subtitle in self.data:
                for word in (task + ' ' + subtitle).split():
                    if word not in vocab:
                        vocab[word] = len(vocab)
        
        return vocab
    
    def _text_to_indices(self, text):
        words = text.split()[:self.max_length-2]
        indices = [self.vocab['<START>']]
        
        for word in words:
            word_idx = self.vocab.get(word, self.vocab['<UNK>'])
            # Ensure index is within vocab range
            if word_idx < len(self.vocab):
                indices.append(word_idx)
            else:
                indices.append(self.vocab['<UNK>'])
        
        indices.append(self.vocab['<END>'])
        
        while len(indices) < self.max_length:
            indices.append(self.vocab['<PAD>'])
            
        return indices[:self.max_length]
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        task, subtitle = self.data[idx]
        
        return {
            'input_ids': torch.tensor(self._text_to_indices(task), dtype=torch.long),
            'target_ids': torch.tensor(self._text_to_indices(subtitle), dtype=torch.long)
        }

class UltraFastModel(nn.Module):
    """Ultra-lightweight model for speed"""
    
    def __init__(self, vocab_size, embed_dim=32, hidden_dim=64):  # Much smaller
        super().__init__()
        
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        self.hidden_dim = hidden_dim
        
        # Minimal architecture for speed
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.encoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.decoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.output_proj = nn.Linear(hidden_dim, vocab_size)
        self.criterion = nn.CrossEntropyLoss(ignore_index=0)
        
    def forward(self, input_ids, target_ids=None):
        # Encode
        input_embeds = self.embedding(input_ids)
        encoder_out, (hidden, cell) = self.encoder(input_embeds)
        
        if target_ids is not None:
            # Training
            target_embeds = self.embedding(target_ids[:, :-1])
            decoder_out, _ = self.decoder(target_embeds, (hidden, cell))
            logits = self.output_proj(decoder_out)
            
            loss = self.criterion(logits.reshape(-1, self.vocab_size), 
                                target_ids[:, 1:].reshape(-1))
            
            return {'loss': loss, 'logits': logits}
        else:
            # Inference mode - FIXED to match training dimensions
            batch_size = input_ids.size(0)
            max_len = input_ids.size(1)
            
            outputs = []
            current_input = self.embedding(torch.full((batch_size, 1), 2, device=input_ids.device))  # START
            decoder_hidden = (hidden, cell)
            
            for step in range(max_len - 1):  # Generate max_len-1 tokens to match target
                decoder_out, decoder_hidden = self.decoder(current_input, decoder_hidden)
                logits = self.output_proj(decoder_out)
                outputs.append(logits)
                
                predicted = torch.argmax(logits, dim=-1)
                current_input = self.embedding(predicted)
            
            return {'logits': torch.cat(outputs, dim=1)}

def create_fast_training_data():
    """Enhanced training data with more examples for better accuracy"""
    
    return [
        # Original data
        ("reading books 7 pm today", [
            "ğŸ“š Literary Adventure at 7:00 PM",
            "ğŸ¯ Knowledge Quest: Reading Session at 7 PM",
            "ğŸ“– Mind Journey: Book Time at 7:00 PM"
        ]),
        ("play cricket today 9 pm", [
            "ğŸ Cricket Championship at 9:00 PM", 
            "âš½ Athletic Excellence: Cricket Match at 9 PM",
            "ğŸ† Sports Victory: Cricket Battle at 9:00 PM"
        ]),
        ("play football 6 pm", [
            "âš½ Field Domination at 6:00 PM",
            "ğŸ† Football Glory: Match Time 6 PM",
            "ğŸ¥… Goal Crusher: Football Action at 6:00 PM"
        ]),
        ("gym workout 8 am", [
            "ğŸ’ª Iron Conquest at 8:00 AM",
            "ğŸ”¥ Fitness Domination: Morning Power 8 AM",
            "ğŸ‹ï¸ Strength Mode: Gym Session at 8:00 AM"
        ]),
        ("meeting at 2 pm", [
            "ğŸ“Š Professional Excellence at 2:00 PM",
            "ğŸ“Š Business Victory: Meeting Time 2 PM",
            "ğŸ¢ Corporate Success: Conference at 2:00 PM"
        ]),
        ("study session 4 pm", [
            "ğŸ“š Academic Victory at 4:00 PM",
            "ğŸ¯ Learning Adventure: Study Time 4 PM",
            "ğŸ§  Brain Power: Knowledge Session at 4:00 PM"
        ]),
        ("shopping mall 3 pm", [
            "ğŸ›’ Shopping Success at 3:00 PM",
            "ğŸ›ï¸ Retail Therapy: Mall Mission 3 PM",
            "ğŸ’³ Purchase Power: Shopping Spree at 3:00 PM"
        ]),
        ("cooking dinner 7 pm", [
            "ğŸ³ Culinary Creation at 7:00 PM",
            "ğŸ‘¨â€ğŸ³ Kitchen Mastery: Dinner Prep 7 PM",
            "ğŸ”¥ Chef Mode: Cooking Excellence at 7:00 PM"
        ]),
        ("swimming pool 5 pm", [
            "ğŸŠ Aquatic Excellence at 5:00 PM",
            "ğŸ’§ Pool Mastery: Swimming Session 5 PM",
            "ğŸŒŠ Water Warrior: Pool Time at 5:00 PM"
        ]),
        ("running park 6 am", [
            "ğŸƒ Speed Demon at 6:00 AM",
            "âš¡ Running Victory: Morning Sprint 6 AM",
            "ğŸŒ… Dawn Runner: Park Session at 6:00 AM"
        ]),
        ("tennis match 4 pm", [
            "ğŸ¾ Ace Champion at 4:00 PM",
            "ğŸ† Tennis Triumph: Match Point 4 PM",
            "ğŸ¯ Court Master: Tennis Battle at 4:00 PM"
        ]),
        ("dance class 8 pm", [
            "ğŸ’ƒ Rhythm Master at 8:00 PM",
            "ğŸµ Dance Excellence: Movement Magic 8 PM",
            "âœ¨ Groove Time: Dance Session at 8:00 PM"
        ]),
        ("movie theater 9 pm", [
            "ğŸ¬ Cinema Adventure at 9:00 PM",
            "ğŸ¿ Movie Magic: Theater Experience 9 PM",
            "ğŸ­ Entertainment Mode: Film Time at 9:00 PM"
        ]),
        ("doctor appointment 10 am", [
            "âš•ï¸ Health Priority at 10:00 AM",
            "ğŸ¥ Wellness Journey: Medical Visit 10 AM",
            "ğŸ’Š Health Excellence: Doctor Time at 10:00 AM"
        ]),
        ("coffee shop 11 am", [
            "â˜• Caffeine Mission at 11:00 AM",
            "ğŸŒŸ Coffee Excellence: Brew Time 11 AM",
            "â˜• Energy Boost: Coffee Session at 11:00 AM"
        ]),
        ("library study 2 pm", [
            "ğŸ“š Knowledge Hub at 2:00 PM",
            "ğŸ¤« Silent Study: Library Focus 2 PM",
            "ğŸ“– Academic Zone: Library Session at 2:00 PM"
        ]),
        ("meeting with client at 2 pm", [
            "Professional Excellence: Client Connection Time",
            "Where Deals Are Made: 2 PM Power Hour",
            "Showtime: Your Client Awaits Your Brilliance",
            "Client Chemistry: Make Every Second Count",
            "The Meeting That Could Change Everything"
        ]),
        ("team meeting at 3 pm tomorrow", [
            "Collaboration Station: Team Power Hour",
            "Tomorrow's Synergy: United We Achieve",
            "3 PM: Where Great Minds Align",
            "Team Spirit Activation: Excellence Together",
            "The Huddle That Fuels Victory"
        ]),
        ("conference call at 9 am", [
            "Digital Boardroom: Your Voice Matters",
            "9 AM Sharp: Professional Communication Mode",
            "Virtual Excellence: Connect and Conquer",
            "Morning Call to Greatness",
            "When Distance Means Nothing: Remote Power"
        ]),
        ("prep meeting agenda today", [
            "Strategic Planning: Agenda Mastery Mode",
            "Organization Wins: Blueprint Your Meeting",
            "The Prep That Separates Good from Great",
            "Agenda Architect: Build Success Framework",
            "Preparation Is Victory: Meeting Ready"
        ]),
        ("client demo at 5 pm", [
            "Spotlight Ready: Your Moment to Shine",
            "Demo Day: Where Features Become Dreams",
            "5 PM Performance: Blow Their Minds",
            "Product Pride: Show What You've Built",
            "The Presentation That Seals the Deal"
        ]),
        
        # NEW DATA - Fitness & Sports
        ("yoga class 7 am", [
            "ğŸ§˜ Morning Zen at 7:00 AM",
            "â˜€ï¸ Mindful Movement: Yoga Flow 7 AM",
            "ğŸ•‰ï¸ Balance Master: Morning Stretch at 7:00 AM"
        ]),
        ("basketball practice 5 pm", [
            "ğŸ€ Hoop Dreams at 5:00 PM",
            "ğŸ”¥ Court Commander: Basketball Drill 5 PM",
            "â›¹ï¸ Slam Dunk Session at 5:00 PM"
        ]),
        ("cycling route 6 am", [
            "ğŸš´ Pedal Power at 6:00 AM",
            "ğŸŒ„ Morning Ride: Cycling Adventure 6 AM",
            "âš¡ Two-Wheel Thunder at 6:00 AM"
        ]),
        ("boxing training 7 pm", [
            "ğŸ¥Š Fight Mode at 7:00 PM",
            "ğŸ’¥ Ring Warrior: Boxing Power 7 PM",
            "ğŸ”¥ Knockout Training at 7:00 PM"
        ]),
        ("pilates session 9 am", [
            "ğŸ¤¸ Core Strength at 9:00 AM",
            "ğŸ’ª Pilates Precision: Control Session 9 AM",
            "âœ¨ Flexibility Flow at 9:00 AM"
        ]),
        
        # Work & Professional
        ("quarterly review 1 pm", [
            "ğŸ“Š Performance Showcase at 1:00 PM",
            "ğŸ’¼ Quarterly Excellence: Review Time 1 PM",
            "ğŸ¯ Progress Report: Achievement Hour at 1:00 PM"
        ]),
        ("brainstorming session 10 am", [
            "ğŸ’¡ Innovation Lab at 10:00 AM",
            "ğŸš€ Creative Explosion: Ideation 10 AM",
            "ğŸ§  Think Tank: Brainstorm Power at 10:00 AM"
        ]),
        ("job interview 11 am", [
            "ğŸ¯ Career Opportunity at 11:00 AM",
            "â­ Interview Excellence: Your Moment 11 AM",
            "ğŸ’¼ Professional Breakthrough at 11:00 AM"
        ]),
        ("workshop training 2 pm", [
            "ğŸ“š Skill Building at 2:00 PM",
            "ğŸ“ Professional Growth: Workshop 2 PM",
            "ğŸ”§ Expertise Upgrade at 2:00 PM"
        ]),
        ("project deadline today", [
            "â° Finish Line Focus: Deadline Day",
            "ğŸ¯ Final Push: Project Completion Mode",
            "ğŸ Victory Lap: Deliver Excellence Today"
        ]),
        
        # Social & Entertainment
        ("birthday party 6 pm", [
            "ğŸ‚ Celebration Time at 6:00 PM",
            "ğŸ‰ Birthday Bash: Party Mode 6 PM",
            "ğŸˆ Joy Fest: Celebration Hour at 6:00 PM"
        ]),
        ("dinner date 8 pm", [
            "ğŸ½ï¸ Romantic Evening at 8:00 PM",
            "â¤ï¸ Date Night: Special Moments 8 PM",
            "ğŸŒ¹ Connection Time: Dinner Date at 8:00 PM"
        ]),
        ("game night 9 pm", [
            "ğŸ® Epic Gaming at 9:00 PM",
            "ğŸ•¹ï¸ Victory Quest: Game Night 9 PM",
            "ğŸ† Championship Hour at 9:00 PM"
        ]),
        ("concert tonight 7 pm", [
            "ğŸ¸ Music Magic at 7:00 PM",
            "ğŸµ Live Performance: Concert Time 7 PM",
            "ğŸ¤ Sound Wave: Music Night at 7:00 PM"
        ]),
        ("picnic park 12 pm", [
            "ğŸ§º Outdoor Feast at 12:00 PM",
            "ğŸŒ³ Nature Break: Picnic Time 12 PM",
            "â˜€ï¸ Sunshine Gathering at 12:00 PM"
        ]),
        
        # Education & Learning
        ("online course 3 pm", [
            "ğŸ’» Digital Learning at 3:00 PM",
            "ğŸ“± Course Progress: Study Time 3 PM",
            "ğŸ“ Knowledge Upgrade at 3:00 PM"
        ]),
        ("exam preparation 5 pm", [
            "ğŸ“ Test Ready at 5:00 PM",
            "ğŸ¯ Exam Excellence: Prep Session 5 PM",
            "ğŸ† Success Mode: Study Power at 5:00 PM"
        ]),
        ("language class 6 pm", [
            "ğŸ—£ï¸ Linguistic Journey at 6:00 PM",
            "ğŸŒ Language Mastery: Learning Hour 6 PM",
            "ğŸ“š Communication Skills at 6:00 PM"
        ]),
        ("tutoring session 4 pm", [
            "ğŸ‘¨â€ğŸ« Learning Boost at 4:00 PM",
            "ğŸ“– Academic Support: Tutoring 4 PM",
            "ğŸ§  Knowledge Transfer at 4:00 PM"
        ]),
        ("research work 1 pm", [
            "ğŸ”¬ Discovery Mode at 1:00 PM",
            "ğŸ“Š Research Excellence: Investigation 1 PM",
            "ğŸ“ Scholar Hour at 1:00 PM"
        ]),
        
        # Health & Wellness
        ("meditation 6 am", [
            "ğŸ§˜â€â™‚ï¸ Inner Peace at 6:00 AM",
            "â˜®ï¸ Mindfulness: Morning Calm 6 AM",
            "ğŸŒ… Zen Mode: Meditation at 6:00 AM"
        ]),
        ("therapy session 3 pm", [
            "ğŸ’­ Mental Wellness at 3:00 PM",
            "ğŸŒ± Growth Journey: Therapy Time 3 PM",
            "ğŸ’š Self-Care Hour at 3:00 PM"
        ]),
        ("dentist appointment 2 pm", [
            "ğŸ¦· Smile Care at 2:00 PM",
            "ğŸ˜ Dental Health: Checkup Time 2 PM",
            "âœ¨ Bright Smile Session at 2:00 PM"
        ]),
        ("spa treatment 4 pm", [
            "ğŸ’† Relaxation Time at 4:00 PM",
            "ğŸŒº Spa Bliss: Pamper Session 4 PM",
            "âœ¨ Rejuvenation Hour at 4:00 PM"
        ]),
        ("nutrition consult 11 am", [
            "ğŸ¥— Wellness Planning at 11:00 AM",
            "ğŸ Nutrition Guide: Health Talk 11 AM",
            "ğŸ’š Fuel Your Body at 11:00 AM"
        ]),
        
        # Daily Tasks & Errands
        ("grocery shopping 5 pm", [
            "ğŸ›’ Fresh Finds at 5:00 PM",
            "ğŸ¥¬ Market Mission: Shopping Time 5 PM",
            "ğŸ Pantry Power at 5:00 PM"
        ]),
        ("laundry today", [
            "ğŸ‘• Fresh Clothes Mission Today",
            "ğŸ§º Laundry Victory: Clean Mode Activated",
            "âœ¨ Wardrobe Refresh: Wash Day"
        ]),
        ("car service 10 am", [
            "ğŸš— Vehicle Care at 10:00 AM",
            "ğŸ”§ Auto Maintenance: Service Time 10 AM",
            "âš™ï¸ Road Ready at 10:00 AM"
        ]),
        ("bank visit 1 pm", [
            "ğŸ¦ Financial Business at 1:00 PM",
            "ğŸ’° Money Matters: Bank Time 1 PM",
            "ğŸ’³ Finance Hour at 1:00 PM"
        ]),
        ("post office 3 pm", [
            "ğŸ“® Mailing Mission at 3:00 PM",
            "âœ‰ï¸ Package Power: Post Time 3 PM",
            "ğŸ“¦ Delivery Prep at 3:00 PM"
        ]),
        
        # Creative & Hobbies
        ("painting session 2 pm", [
            "ğŸ¨ Artistic Flow at 2:00 PM",
            "ğŸ–Œï¸ Creative Canvas: Paint Time 2 PM",
            "ğŸŒˆ Color Magic at 2:00 PM"
        ]),
        ("photography walk 5 pm", [
            "ğŸ“¸ Capture Moments at 5:00 PM",
            "ğŸŒ† Photo Adventure: Golden Hour 5 PM",
            "ğŸ“· Visual Journey at 5:00 PM"
        ]),
        ("guitar practice 7 pm", [
            "ğŸ¸ String Mastery at 7:00 PM",
            "ğŸµ Music Practice: Guitar Session 7 PM",
            "ğŸ¶ Melody Maker at 7:00 PM"
        ]),
        ("writing time 9 pm", [
            "âœï¸ Creative Words at 9:00 PM",
            "ğŸ“ Author Mode: Writing Hour 9 PM",
            "ğŸ“– Story Craft at 9:00 PM"
        ]),
        ("gardening 8 am", [
            "ğŸŒ» Green Thumb at 8:00 AM",
            "ğŸŒ± Garden Glory: Plant Time 8 AM",
            "ğŸŒ¿ Nature Nurture at 8:00 AM"
        ]),
        
        # Family & Home
        ("family dinner 7 pm", [
            "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Together Time at 7:00 PM",
            "ğŸ½ï¸ Family Feast: Bonding Hour 7 PM",
            "â¤ï¸ Home Gathering at 7:00 PM"
        ]),
        ("kids pickup 3 pm", [
            "ğŸš¸ Parent Duty at 3:00 PM",
            "ğŸ‘¶ Family First: Pickup Time 3 PM",
            "ğŸ« School Run at 3:00 PM"
        ]),
        ("house cleaning 10 am", [
            "ğŸ§¹ Home Refresh at 10:00 AM",
            "âœ¨ Clean Sweep: Tidy Time 10 AM",
            "ğŸ  Space Revival at 10:00 AM"
        ]),
        ("pet vet 2 pm", [
            "ğŸ• Pet Care at 2:00 PM",
            "ğŸ¾ Furry Friend Health: Vet Visit 2 PM",
            "â¤ï¸ Animal Wellness at 2:00 PM"
        ]),
        ("home repair 11 am", [
            "ğŸ”¨ Fix-It Time at 11:00 AM",
            "ğŸ  Home Improvement: Repair Hour 11 AM",
            "ğŸ”§ DIY Mode at 11:00 AM"
        ]),
        
        # Travel & Transportation
        ("flight departure 6 am", [
            "âœˆï¸ Journey Begins at 6:00 AM",
            "ğŸŒ Travel Adventure: Takeoff 6 AM",
            "ğŸ§³ Sky Bound at 6:00 AM"
        ]),
        ("train commute 8 am", [
            "ğŸš„ Morning Transit at 8:00 AM",
            "ğŸš‰ Commute Time: Train Ride 8 AM",
            "ğŸ« Rail Journey at 8:00 AM"
        ]),
        ("airport pickup 9 pm", [
            "ğŸ›¬ Welcome Back at 9:00 PM",
            "ğŸš— Airport Run: Pickup Mission 9 PM",
            "ğŸ‘‹ Arrival Time at 9:00 PM"
        ]),
        ("road trip 5 am", [
            "ğŸš— Adventure Awaits at 5:00 AM",
            "ğŸ›£ï¸ Road Warrior: Trip Start 5 AM",
            "ğŸ—ºï¸ Journey Quest at 5:00 AM"
        ]),
        ("taxi booking 7 pm", [
            "ğŸš• Ride Ready at 7:00 PM",
            "ğŸ“± Transport Sorted: Taxi Time 7 PM",
            "ğŸš– On The Move at 7:00 PM"
        ]),
        
        # Technology & Digital
        ("webinar 4 pm", [
            "ğŸ’» Virtual Learning at 4:00 PM",
            "ğŸŒ Digital Session: Webinar Time 4 PM",
            "ğŸ“¡ Online Event at 4:00 PM"
        ]),
        ("podcast recording 6 pm", [
            "ğŸ™ï¸ Audio Magic at 6:00 PM",
            "ğŸ§ Podcast Power: Recording Session 6 PM",
            "ğŸ“» Voice Time at 6:00 PM"
        ]),
        ("software update today", [
            "âš™ï¸ System Upgrade: Update Mission Today",
            "ğŸ’¾ Tech Refresh: Software Patch Time",
            "ğŸ”„ Digital Renewal: Update Ready"
        ]),
        ("video call 3 pm", [
            "ğŸ“¹ Face Time at 3:00 PM",
            "ğŸ’¬ Virtual Connect: Video Chat 3 PM",
            "ğŸ‘¥ Screen Meeting at 3:00 PM"
        ]),
        ("backup data 11 pm", [
            "ğŸ’¾ Data Guardian at 11:00 PM",
            "ğŸ”’ Security Mode: Backup Time 11 PM",
            "ğŸ“Š Digital Safety at 11:00 PM"
        ])
    ]

def calculate_fast_accuracy(model, dataloader, device):
    """Quick accuracy calculation - FIXED tensor size issue"""
    model.eval()
    
    total_correct = 0
    total_tokens = 0
    
    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch['input_ids'].to(device)
            target_ids = batch['target_ids'].to(device)
            
            outputs = model(input_ids)
            logits = outputs['logits']
            predicted = torch.argmax(logits, dim=-1)
            
            # Fix tensor size mismatch - ensure same dimensions
            seq_len = min(predicted.size(1), target_ids.size(1) - 1)
            
            predicted_trimmed = predicted[:, :seq_len]
            target_trimmed = target_ids[:, 1:1+seq_len]  # Skip START token, match length
            
            mask = target_trimmed != 0  # Ignore padding
            correct = (predicted_trimmed == target_trimmed) & mask
            
            total_correct += correct.sum().item()
            total_tokens += mask.sum().item()
    
    return total_correct / max(1, total_tokens)

def ultra_fast_train():
    """Ultra-fast training - complete in under 2 minutes"""
    print("ğŸš€ ULTRA FAST TRAINING - TARGET: <2 MINUTES")
    print("="*60)
    
    start_time = time.time()
    
    # Create minimal data
    training_data = create_fast_training_data()
    print(f"ğŸ“Š Training examples: {len(training_data)}")
    
    # Split data - FIXED to ensure proper train/val split
    total_examples = len(training_data)
    train_size = max(1, int(total_examples * 0.75))  # 75% for training
    
    train_data = training_data[:train_size]
    val_data = training_data[train_size:] if train_size < total_examples else training_data[-2:]  # Ensure at least 2 for validation
    
    print(f"ğŸ“Š Data split: {len(train_data)} train, {len(val_data)} validation")
    
    # Create datasets with small batch size for speed
    train_dataset = FastDataset(train_data, max_length=20, vocab_file='vocab.txt')
    val_dataset = FastDataset(val_data, max_length=10, vocab_file='vocab.txt')
    
    # Use the same vocab for both datasets
    val_dataset.vocab = train_dataset.vocab
    val_dataset.vocab_size = train_dataset.vocab_size
    
    vocab = train_dataset.vocab
    vocab_size = len(vocab)
    
    print(f"ğŸ“Š Vocab size: {vocab_size}")
    print(f"ğŸ“Š Train samples: {len(train_dataset)}")
    print(f"ğŸ“Š Val samples: {len(val_dataset)}")
    
    # Debug: Check vocab indices
    max_idx = max(vocab.values())
    print(f"ğŸ“Š Max vocab index: {max_idx}")
    
    # Fast data loaders
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Smaller batch
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)
    
    # Ultra-lightweight model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = UltraFastModel(vocab_size=vocab_size, embed_dim=32, hidden_dim=64)
    model.to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ¤– Model parameters: {total_params:,}")
    print(f"ğŸ”¥ Training on: {device}")
    
    # Fast optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3, weight_decay=0.01)
    
    # Ultra-fast training - MORE EPOCHS for better accuracy
    num_epochs = 15  # Increased from 3 to 15
    training_history = []
    
    print(f"\nğŸ¯ Starting {num_epochs} epochs for better accuracy...")
    print("="*60)
    
    best_accuracy = 0.0
    
    for epoch in range(num_epochs):
        epoch_start = time.time()
        
        # Training
        model.train()
        total_loss = 0
        batches = 0
        
        for batch in train_loader:
            optimizer.zero_grad()
            
            input_ids = batch['input_ids'].to(device)
            target_ids = batch['target_ids'].to(device)
            
            outputs = model(input_ids, target_ids)
            loss = outputs['loss']
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            batches += 1
        
        avg_loss = total_loss / batches
        
        # Quick validation
        val_accuracy = calculate_fast_accuracy(model, val_loader, device)
        train_accuracy = calculate_fast_accuracy(model, train_loader, device)
        
        epoch_time = time.time() - epoch_start
        
        # Save immediately after each epoch
        epoch_model = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'vocab': vocab,
            'val_accuracy': val_accuracy,
            'train_accuracy': train_accuracy,
            'loss': avg_loss,
            'timestamp': datetime.now().isoformat()
        }
        
        model_path = f'fast_model_epoch_{epoch+1:02d}.pth'
        torch.save(epoch_model, model_path)
        
        # Track best accuracy
        is_best = val_accuracy > best_accuracy
        if is_best:
            best_accuracy = val_accuracy
            # Save as best model
            torch.save(epoch_model, 'best_fast_model.pth')
        
        # Progress indicator
        progress = (epoch + 1) / num_epochs * 100
        
        print(f"ğŸ“Š EPOCH {epoch+1:2d}/{num_epochs} | Time: {epoch_time:.1f}s | Progress: {progress:5.1f}%")
        print(f"   Loss: {avg_loss:.4f} | Train: {train_accuracy*100:5.1f}% | Val: {val_accuracy*100:5.1f}%", end="")
        
        if is_best:
            print(f" ğŸ† NEW BEST!")
        else:
            print(f" (Best: {best_accuracy*100:.1f}%)")
        
        print(f"   ğŸ’¾ Saved: {model_path}")
        
        training_history.append({
            'epoch': epoch + 1,
            'loss': avg_loss,
            'train_accuracy': train_accuracy,
            'val_accuracy': val_accuracy,
            'time': epoch_time,
            'is_best': is_best
        })
        
        # Show improvement trend every 5 epochs
        if (epoch + 1) % 5 == 0:
            recent_acc = [h['val_accuracy'] for h in training_history[-5:]]
            trend = "ğŸ“ˆ" if recent_acc[-1] > recent_acc[0] else "ğŸ“‰" if recent_acc[-1] < recent_acc[0] else "â¡ï¸"
            print(f"   {trend} 5-epoch trend: {recent_acc[0]*100:.1f}% â†’ {recent_acc[-1]*100:.1f}%")
            print()
    
    # Save final model with best accuracy info
    final_model = {
        'model_state_dict': model.state_dict(),
        'vocab': vocab,
        'training_history': training_history,
        'best_accuracy': best_accuracy,
        'final_accuracy': training_history[-1]['val_accuracy'],
        'total_epochs': num_epochs,
        'model_config': {
            'vocab_size': vocab_size,
            'embed_dim': 32,
            'hidden_dim': 64
        }
    }
    
    torch.save(final_model, 'ultra_fast_subtitle_model_enhanced.pth')
    
    total_time = time.time() - start_time
    
    # Save training history with enhanced info
    with open('enhanced_fast_training_history.json', 'w') as f:
        json.dump({
            'training_history': training_history,
            'summary': {
                'total_epochs': num_epochs,
                'best_accuracy': best_accuracy,
                'final_accuracy': training_history[-1]['val_accuracy'],
                'total_time': total_time,
                'improvement': training_history[-1]['val_accuracy'] - training_history[0]['val_accuracy'],
                'training_examples': len(training_data),
                'vocab_size': vocab_size,
                'model_params': total_params
            }
        }, f, indent=2)
    
    total_time = time.time() - start_time
    
    print(f"\nğŸ‰ ENHANCED ULTRA FAST TRAINING COMPLETED!")
    print("="*60)
    print(f"â±ï¸  Total Time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)")
    print(f"ğŸ¯ Final Accuracy: {training_history[-1]['val_accuracy']*100:.1f}%")
    print(f"ğŸ† Best Accuracy: {best_accuracy*100:.1f}%")
    print(f"ğŸ“ˆ Improvement: {(training_history[-1]['val_accuracy'] - training_history[0]['val_accuracy'])*100:+.1f}%")
    print(f"ğŸ’¾ Models saved: {num_epochs} epoch models + 1 best + 1 final")
    print(f"ğŸ“Š History saved: enhanced_fast_training_history.json")
    
    # Show training progression summary
    print(f"\nğŸ“Š TRAINING PROGRESSION:")
    print("="*60)
    milestones = [0, 4, 9, 14]  # Show epochs 1, 5, 10, 15
    for i in milestones:
        if i < len(training_history):
            h = training_history[i]
            marker = "ğŸ†" if h.get('is_best', False) else "ğŸ“Š"
            print(f"{marker} Epoch {h['epoch']:2d}: Loss {h['loss']:.3f} | Val Acc {h['val_accuracy']*100:5.1f}%")
    
    if total_time < 300:  # 5 minutes
        print(f"\nâœ… SUCCESS: Completed {num_epochs} epochs in under 5 minutes!")
    else:
        print(f"\nâš ï¸  Took {total_time:.1f}s for {num_epochs} epochs")
    
    print(f"\nğŸš€ Ready to generate better subtitles with {best_accuracy*100:.1f}% accuracy!")
    
    return model, vocab, training_history

if __name__ == "__main__":
    model, vocab, history = ultra_fast_train()